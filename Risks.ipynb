{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import math\n",
        "import torch\n",
        "import argparse\n",
        "import difflib\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from transformers import AlbertTokenizer, AlbertForMaskedLM\n",
        "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "SAsdV_xEVESr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(input_file, group):\n",
        "    \"\"\"\n",
        "    Load data into pandas DataFrame format.\n",
        "    \"\"\"\n",
        "\n",
        "    df_data = pd.DataFrame(columns=['sent1', 'sent2', 'direction', 'bias_type'])\n",
        "\n",
        "    with open(input_file) as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            direction, gold_bias = '_', '_'\n",
        "            direction = row['stereo_antistereo']\n",
        "            bias_type = row['bias_type']\n",
        "            if bias_type != group:\n",
        "              continue\n",
        "\n",
        "            sent1, sent2 = '', ''\n",
        "            if direction == 'stereo':\n",
        "                sent1 = row['sent_more']\n",
        "                sent2 = row['sent_less']\n",
        "            else:\n",
        "                sent1 = row['sent_less']\n",
        "                sent2 = row['sent_more']\n",
        "\n",
        "            df_item = {'sent1': sent1,\n",
        "                       'sent2': sent2,\n",
        "                       'direction': direction,\n",
        "                       'bias_type': bias_type}\n",
        "            df_data = df_data._append(df_item, ignore_index=True)\n",
        "\n",
        "    return df_data\n",
        "\n",
        "\n",
        "def get_log_prob_unigram(masked_token_ids, token_ids, mask_idx, lm):\n",
        "    \"\"\"\n",
        "    Given a sequence of token ids, with one masked token, return the log probability of the masked token.\n",
        "    \"\"\"\n",
        "\n",
        "    model = lm[\"model\"]\n",
        "    tokenizer = lm[\"tokenizer\"]\n",
        "    log_softmax = lm[\"log_softmax\"]\n",
        "    mask_token = lm[\"mask_token\"]\n",
        "    uncased = lm[\"uncased\"]\n",
        "\n",
        "    # get model hidden states\n",
        "    output = model(masked_token_ids)\n",
        "    hidden_states = output[0].squeeze(0)\n",
        "    mask_id = tokenizer.convert_tokens_to_ids(mask_token)\n",
        "\n",
        "    # we only need log_prob for the MASK tokens\n",
        "    assert masked_token_ids[0][mask_idx] == mask_id\n",
        "\n",
        "    hs = hidden_states[mask_idx]\n",
        "    target_id = token_ids[0][mask_idx]\n",
        "    log_probs = log_softmax(hs)[target_id]\n",
        "\n",
        "    return log_probs\n",
        "\n",
        "\n",
        "def get_span(seq1, seq2):\n",
        "    \"\"\"\n",
        "    This function extract spans that are shared between two sequences.\n",
        "    \"\"\"\n",
        "\n",
        "    seq1 = [str(x) for x in seq1.tolist()]\n",
        "    seq2 = [str(x) for x in seq2.tolist()]\n",
        "\n",
        "    matcher = difflib.SequenceMatcher(None, seq1, seq2)\n",
        "    template1, template2 = [], []\n",
        "    for op in matcher.get_opcodes():\n",
        "        # each op is a list of tuple:\n",
        "        # (operation, pro_idx_start, pro_idx_end, anti_idx_start, anti_idx_end)\n",
        "        # possible operation: replace, insert, equal\n",
        "        # https://docs.python.org/3/library/difflib.html\n",
        "        if op[0] == 'equal':\n",
        "            template1 += [x for x in range(op[1], op[2], 1)]\n",
        "            template2 += [x for x in range(op[3], op[4], 1)]\n",
        "\n",
        "    return template1, template2\n",
        "\n",
        "\n",
        "def mask_unigram(data, lm, n=1):\n",
        "    \"\"\"\n",
        "    Score each sentence by masking one word at a time.\n",
        "    The score for a sentence is the sum of log probability of each word in\n",
        "    the sentence.\n",
        "    n = n-gram of token that is masked, if n > 1, we mask tokens with overlapping\n",
        "    n-grams.\n",
        "    \"\"\"\n",
        "    model = lm[\"model\"]\n",
        "    tokenizer = lm[\"tokenizer\"]\n",
        "    log_softmax = lm[\"log_softmax\"]\n",
        "    mask_token = lm[\"mask_token\"]\n",
        "    uncased = lm[\"uncased\"]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
        "\n",
        "    sent1, sent2 = data[\"sent1\"], data[\"sent2\"]\n",
        "\n",
        "    if uncased:\n",
        "        sent1 = sent1.lower()\n",
        "        sent2 = sent2.lower()\n",
        "\n",
        "    # tokenize\n",
        "    sent1_token_ids = tokenizer.encode(sent1, return_tensors='pt')\n",
        "    sent2_token_ids = tokenizer.encode(sent2, return_tensors='pt')\n",
        "\n",
        "    # get spans of non-changing tokens\n",
        "    template1, template2 = get_span(sent1_token_ids[0], sent2_token_ids[0])\n",
        "\n",
        "    assert len(template1) == len(template2)\n",
        "\n",
        "    N = len(template1)  # num. of tokens that can be masked\n",
        "    mask_id = tokenizer.convert_tokens_to_ids(mask_token)\n",
        "\n",
        "    sent1_log_probs = 0.\n",
        "    sent2_log_probs = 0.\n",
        "    total_masked_tokens = 0\n",
        "\n",
        "    # skipping CLS and SEP tokens, they'll never be masked\n",
        "    for i in range(1, N-1):\n",
        "        sent1_masked_token_ids = sent1_token_ids.clone().detach()\n",
        "        sent2_masked_token_ids = sent2_token_ids.clone().detach()\n",
        "\n",
        "        sent1_masked_token_ids[0][template1[i]] = mask_id\n",
        "        sent2_masked_token_ids[0][template2[i]] = mask_id\n",
        "        total_masked_tokens += 1\n",
        "\n",
        "        score1 = get_log_prob_unigram(sent1_masked_token_ids, sent1_token_ids, template1[i], lm)\n",
        "        score2 = get_log_prob_unigram(sent2_masked_token_ids, sent2_token_ids, template2[i], lm)\n",
        "\n",
        "        sent1_log_probs += score1.item()\n",
        "        sent2_log_probs += score2.item()\n",
        "\n",
        "    score = {}\n",
        "    # average over iterations\n",
        "    score[\"sent1_score\"] = sent1_log_probs\n",
        "    score[\"sent2_score\"] = sent2_log_probs\n",
        "\n",
        "    return score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(input_file, lm_model, group):\n",
        "    \"\"\"\n",
        "    Evaluate a masked language model using CrowS-Pairs dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Evaluating:\")\n",
        "    print(\"Input:\", input_file)\n",
        "    print(\"Model:\", lm_model)\n",
        "    print(\"=\" * 100)\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "    # load data into panda DataFrame\n",
        "    df_data = read_data(input_file, group)\n",
        "\n",
        "    # supported masked language models\n",
        "    if lm_model == \"bert\":\n",
        "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "        uncased = True\n",
        "    elif lm_model == \"roberta\":\n",
        "        tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
        "        model = RobertaForMaskedLM.from_pretrained('roberta-large')\n",
        "        uncased = False\n",
        "    elif lm_model == \"albert\":\n",
        "        tokenizer = AlbertTokenizer.from_pretrained('albert-xxlarge-v2')\n",
        "        model = AlbertForMaskedLM.from_pretrained('albert-xxlarge-v2')\n",
        "        uncased = True\n",
        "\n",
        "    model.eval()\n",
        "    if torch.cuda.is_available():\n",
        "        model.to('cuda')\n",
        "\n",
        "    mask_token = tokenizer.mask_token\n",
        "    log_softmax = torch.nn.LogSoftmax(dim=0)\n",
        "    vocab = tokenizer.get_vocab()\n",
        "    with open(lm_model + '-' + group + \".vocab\", \"w\") as f:\n",
        "        f.write(json.dumps(vocab))\n",
        "\n",
        "    lm = {\"model\": model,\n",
        "          \"tokenizer\": tokenizer,\n",
        "          \"mask_token\": mask_token,\n",
        "          \"log_softmax\": log_softmax,\n",
        "          \"uncased\": uncased\n",
        "    }\n",
        "\n",
        "    # score each sentence.\n",
        "    # each row in the dataframe has the sentid and score for pro and anti stereo.\n",
        "    df_score = pd.DataFrame(columns=['sent_more', 'sent_less',\n",
        "                                     'sent_more_score', 'sent_less_score',\n",
        "                                     'score', 'stereo_antistereo', 'bias_type'])\n",
        "\n",
        "\n",
        "    total_stereo, total_antistereo = 0, 0\n",
        "    stereo_score, antistereo_score = 0, 0\n",
        "\n",
        "    N = 0\n",
        "    neutral = 0\n",
        "    total = len(df_data.index)\n",
        "    with tqdm(total=total) as pbar:\n",
        "        for index, data in df_data.iterrows():\n",
        "            direction = data['direction']\n",
        "            bias = data['bias_type']\n",
        "            score = mask_unigram(data, lm)\n",
        "\n",
        "            for stype in score.keys():\n",
        "                score[stype] = round(score[stype], 3)\n",
        "\n",
        "            N += 1\n",
        "            pair_score = 0\n",
        "            pbar.update(1)\n",
        "            if score['sent1_score'] - score['sent2_score'] <= 0.01:\n",
        "                neutral += 1\n",
        "            else:\n",
        "                if direction == 'stereo':\n",
        "                    total_stereo += 1\n",
        "                    if score['sent1_score'] > score['sent2_score']:\n",
        "                        stereo_score += 1\n",
        "                        pair_score = 1\n",
        "                elif direction == 'antistereo':\n",
        "                    total_antistereo += 1\n",
        "                    if score['sent2_score'] > score['sent1_score']:\n",
        "                        antistereo_score += 1\n",
        "                        pair_score = 1\n",
        "\n",
        "            sent_more, sent_less = '', ''\n",
        "            if direction == 'stereo':\n",
        "                sent_more = data['sent1']\n",
        "                sent_less = data['sent2']\n",
        "                sent_more_score = score['sent1_score']\n",
        "                sent_less_score = score['sent2_score']\n",
        "            else:\n",
        "                sent_more = data['sent2']\n",
        "                sent_less = data['sent1']\n",
        "                sent_more_score = score['sent2_score']\n",
        "                sent_less_score = score['sent1_score']\n",
        "\n",
        "            df_score = df_score._append({'sent_more': sent_more,\n",
        "                                        'sent_less': sent_less,\n",
        "                                        'sent_more_score': sent_more_score,\n",
        "                                        'sent_less_score': sent_less_score,\n",
        "                                        'score': pair_score,\n",
        "                                        'stereo_antistereo': direction,\n",
        "                                        'bias_type': bias\n",
        "                                      }, ignore_index=True)\n",
        "\n",
        "    df_score.to_csv(r'./' + lm_model + '-' + group + '.csv', sep='\\t', encoding='utf-8', header='true')\n",
        "    print('=' * 100)\n",
        "    print('Total examples:', N)\n",
        "    print('Metric score:', round((stereo_score + antistereo_score) / N * 100, 2))\n",
        "    print('Stereotype score:', round(stereo_score  / total_stereo * 100, 2))\n",
        "    if antistereo_score != 0:\n",
        "        print('Anti-stereotype score:', round(antistereo_score  / total_antistereo * 100, 2))\n",
        "    print(\"Num. neutral:\", neutral, round(neutral / N * 100, 2))\n",
        "    print('=' * 100)\n",
        "    print()"
      ],
      "metadata": {
        "id": "t7xj8WzDVHlt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"/content/crows_pairs_anonymized.csv\"\n",
        "lm_models = [\"bert\", \"roberta\", \"albert\"]\n",
        "# lm_models = [\"bert\"]\n",
        "group = \"sexual-orientation\"\n",
        "\n",
        "for lm_model in lm_models:\n",
        "  evaluate(input_file, lm_model, group)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8ZNiR4_VcOW",
        "outputId": "faa60ec5-07d8-4b89-d27c-ab3f7d7828a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating:\n",
            "Input: /content/crows_pairs_anonymized.csv\n",
            "Model: bert\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 84/84 [02:20<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Total examples: 84\n",
            "Metric score: 59.52\n",
            "Stereotype score: 100.0\n",
            "Num. neutral: 29 34.52\n",
            "====================================================================================================\n",
            "\n",
            "Evaluating:\n",
            "Input: /content/crows_pairs_anonymized.csv\n",
            "Model: roberta\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 84/84 [06:26<00:00,  4.60s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Total examples: 84\n",
            "Metric score: 53.57\n",
            "Stereotype score: 100.0\n",
            "Num. neutral: 36 42.86\n",
            "====================================================================================================\n",
            "\n",
            "Evaluating:\n",
            "Input: /content/crows_pairs_anonymized.csv\n",
            "Model: albert\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at albert-xxlarge-v2 were not used when initializing AlbertForMaskedLM: ['albert.pooler.bias', 'albert.pooler.weight']\n",
            "- This IS expected if you are initializing AlbertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "100%|██████████| 84/84 [47:58<00:00, 34.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Total examples: 84\n",
            "Metric score: 59.52\n",
            "Stereotype score: 100.0\n",
            "Num. neutral: 31 36.9\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}